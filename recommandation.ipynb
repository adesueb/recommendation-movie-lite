{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0, 0, 2]], 4], [[[0, 0, 1]], 1], [[[0, 0, 3]], 5], [[[0, 0, 4]], 7], [[[0, 3, 1]], 3]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Activation, Embedding, Conv1D, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from dataprocessing.find_top_movie_with_sequence import find_top_dataset\n",
    "from dataprocessing.label_and_feature import getSortedClassContents, checkConsists, buildFeature, saveClassesToFile\n",
    "from dataprocessing.time import checkingTimeDifferent\n",
    "from recom_model import trainWithBidirectional,trainWithEmbeddingDense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CONTENTS_ON_USER = 250\n",
    "MAX_DAYS = 7\n",
    "MAX_SEQUENCE = 6\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "recommandation_df = pd.read_csv('{}/normalizedata.csv'.format(DATA_DIR)).sort_values(by=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 15, 23, 39, 69, 79, 162, 169, 202, 205, 213, 252, 255, 306, 308, 312, 322, 369, 371, 379, 434, 448, 455, 478, 479, 480, 481, 492, 507, 513, 535, 548, 623, 626, 640, 644, 657, 682, 683, 697, 700, 752, 772, 776, 777, 781, 824, 832, 839, 883, 913, 936, 960, 964, 977, 989, 993, 1006, 1020, 1026, 1115, 1137, 1185, 1187, 1193, 1239, 1242, 1256, 1269, 1304, 1310, 1397, 1415, 1420, 1428, 1429, 1433, 1436, 1437, 1490, 1498, 1506, 1512, 1521, 1534, 1554, 1559, 1567, 1578, 1579, 1589, 1591, 1599, 1602, 1606, 1607, 1609, 1619, 1620, 1624, 1641, 1652, 1659, 1677, 1700, 1716, 1719, 1756, 1758, 1774, 1777, 1781, 1788, 1790, 1791, 1795, 1798, 1806, 1807, 1813, 1819, 1823, 1826, 1830, 1833, 1834, 1836, 1838, 1839, 1840, 1845, 1847, 1853, 1855, 1862, 1863, 1872, 1873, 1876, 1877, 1879, 1885, 1896, 1910, 1912, 1913, 1927, 1928, 1935, 1936]\n",
      "151\n"
     ]
    }
   ],
   "source": [
    "sortedClassContents = getSortedClassContents(recommandation_df, MIN_CONTENTS_ON_USER)\n",
    "saveClassesToFile(sortedClassContents)\n",
    "lenSortedClassContents = len(sortedClassContents)\n",
    "print(lenSortedClassContents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start = 2020-11-15 18:03:50.094576\n",
      "training size:  8940\n",
      "end = 2020-11-15 18:13:56.830710\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    " \n",
    "print(\"start =\", now)\n",
    "\n",
    "visitors_df = recommandation_df['visitor'].drop_duplicates()\n",
    "maxItem = recommandation_df['Content'].max()\n",
    "training_data = []\n",
    "for index, item in visitors_df.iteritems():\n",
    "    video = recommandation_df[recommandation_df['visitor'] == item]\n",
    "    if video.size > 1:\n",
    "        tempContents = []\n",
    "        indexContent = 0\n",
    "        for index, item in video['Content'].iteritems():\n",
    "            if item not in sortedClassContents:\n",
    "                continue\n",
    "            if len(tempContents) > MAX_SEQUENCE:\n",
    "                tempContents = tempContents[1:]\n",
    "                continue\n",
    "            if checkConsists(item, tempContents):\n",
    "                continue\n",
    "            if len(tempContents) > 0:\n",
    "                nowDate = video['time'].iloc[indexContent]\n",
    "                beforeDate = video['time'].iloc[indexContent - 1]\n",
    "\n",
    "                if checkingTimeDifferent(nowDate, beforeDate, MAX_DAYS):\n",
    "                    tempContents = []\n",
    "                else:\n",
    "                    feature = buildFeature(tempContents, sortedClassContents, MAX_SEQUENCE)\n",
    "                    label = sortedClassContents.index(item)\n",
    "                    training_data.append([[feature], label])\n",
    "            tempContents.append(item)\n",
    "            indexContent += 1\n",
    "\n",
    "training_data = find_top_dataset(training_data)\n",
    "print(\"training size: \", len(training_data))\n",
    "random.shuffle(training_data)\n",
    "\n",
    "now = datetime.now()\n",
    " \n",
    "print(\"end =\", now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "labels = []\n",
    "for feature, label in training_data:\n",
    "    features.append(feature)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(features)\n",
    "Y = np.array(labels)\n",
    "print(X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lstm with embedding\n",
    "X = np.squeeze(X, axis=1)\n",
    "model = trainWithBidirectional(MAX_SEQUENCE, lenSortedClassContents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pure lstm\n",
    "\n",
    "X = np.squeeze(X, axis=1)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=X.shape[1:], return_sequences=True) )\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(lenSortedClassContents))\n",
    "model.add(Activation(\"softmax\"))\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dense\n",
    "X = np.squeeze(X, axis=1)\n",
    "print(X.shape)\n",
    "model = Sequential()   \n",
    "model.add(Dense(512, activation=\"relu\", input_shape=(X.shape[1:])))\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dense(lenSortedClassContents))\n",
    "model.add(Activation(\"softmax\"))\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for embedding Dense\n",
    "X = np.squeeze(X, axis=1)\n",
    "model = trainWithEmbeddingDense(MAX_SEQUENCE, lenSortedClassContents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"testing-1\"\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(name))\n",
    "history = model.fit(X, Y, epochs=250, batch_size=64, verbose=1, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get5TopPredict(predict):\n",
    "    predicts = predict[0].argsort()[-5:][::-1]\n",
    "    for i in predicts:\n",
    "        print(sortedClassContents[i])\n",
    "        \n",
    "def predict(first, second, third, forth, fifth, sixth):\n",
    "    predict = model.predict([[[sortedClassContents.index(first)],[sortedClassContents.index(second)],[sortedClassContents.index(third)],[sortedClassContents.index(forth)], [sortedClassContents.index(fifth)],[sortedClassContents.index(sixth)]]])\n",
    "    get5TopPredict(predict)\n",
    "    return sortedClassContents[np.argmax(predict[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictResult = predictDense(0,0,0,0,700,1756)\n",
    "print(predictResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model = tf.function(lambda x: model(x))\n",
    "# This is important, let's fix the input size.\n",
    "concrete_func = run_model.get_concrete_function(\n",
    "    tf.TensorSpec([1,6], model.inputs[0].dtype))\n",
    "\n",
    "# model directory.\n",
    "MODEL_DIR = \"model\"\n",
    "model.save(MODEL_DIR, save_format=\"tf\", signatures=concrete_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"model\"\n",
    "model.save(MODEL_DIR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model with TensorFlow to get expected results.\n",
    "TEST_CASES = 10\n",
    "\n",
    "# Run the model with TensorFlow Lite\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)\n",
    "print(input_details[0][\"index\"])\n",
    "for i in range(TEST_CASES):\n",
    "  expected = model.predict([[0,0,0,i]])\n",
    "  interpreter.set_tensor( input_details[0][\"index\"], np.array([[0,0,0,i]]).astype(np.float32))\n",
    "  interpreter.invoke()\n",
    "  result = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "\n",
    "  # Assert if the result of TFLite model is consistent with the TF model.\n",
    "  np.testing.assert_almost_equal(expected, result)\n",
    "  print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")\n",
    "\n",
    "  # Please note: TfLite fused Lstm kernel is stateful, so we need to reset\n",
    "  # the states.\n",
    "  # Clean up internal states.\n",
    "  interpreter.reset_all_variables()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"tf_model/converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor( input_details[0][\"index\"], np.array([[0,0,0,sortedClassContents.index(700)]]).astype(np.float32))\n",
    "interpreter.invoke()\n",
    "result = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "print(sortedClassContents[np.argmax(result)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
