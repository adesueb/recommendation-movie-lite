{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional,BatchNormalization, Activation, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CONTENTS_ON_USER = 250\n",
    "MAX_DAYS = 7\n",
    "MAX_SEQUENCE = 6\n",
    "DATA_DIR = \"data\"\n",
    "recommandation_df = pd.read_csv('{}/normalizedata.csv'.format(DATA_DIR)).sort_values(by=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToTimemillis(date):\n",
    "    try:\n",
    "        d = datetime.datetime.strptime(date, \"%Y-%m-%d %H:%M:%S\").strftime('%s.%f')\n",
    "        return int(float(d)*1000)\n",
    "    except:\n",
    "        pass\n",
    "    return 0\n",
    "\n",
    "def getSortedClass():\n",
    "    levels = []\n",
    "    levels.append([0, MIN_CONTENTS_ON_USER+1])\n",
    "    contentLevels = recommandation_df['Content'].values\n",
    "    for contentLevel in contentLevels:\n",
    "        add = True\n",
    "        indexLevel = 0\n",
    "        for key, level in levels:\n",
    "            if contentLevel == key:\n",
    "                add = False\n",
    "                levels[indexLevel] = ([key, level+1])\n",
    "                break\n",
    "            else:\n",
    "                indexLevel+=1\n",
    "        if add:\n",
    "            levels.append([contentLevel, 1])\n",
    "\n",
    "    classContents = []\n",
    "    for key, level in levels:\n",
    "        if level > MIN_CONTENTS_ON_USER:\n",
    "            classContents.append(key)\n",
    "            \n",
    "    sortedClassContents = sorted(classContents)\n",
    "    print(sortedClassContents)\n",
    "    return sortedClassContents\n",
    "\n",
    "def saveClassesToFile(classes):\n",
    "    label_file = open(\"label.txt\", \"w\")\n",
    "    np.savetxt(label_file, classes)\n",
    "    label_file.close()\n",
    "\n",
    "\n",
    "def checkingTimeDifferent(nowDate, beforeDate):\n",
    "    now = convertToTimemillis(nowDate)\n",
    "    before = convertToTimemillis(beforeDate)\n",
    "    return (now - before) >  (MAX_DAYS * 86400000)\n",
    "\n",
    "\n",
    "def buildFeature(paramsContents, sortedClassContents):\n",
    "    feature = []\n",
    "    for ignore in range(MAX_SEQUENCE-len(paramsContents)):\n",
    "        feature.append(0)\n",
    "    for content in paramsContents:\n",
    "        feature.append(sortedClassContents.index(content))\n",
    "        \n",
    "    return feature\n",
    "\n",
    "def checkConsists(item, contents):\n",
    "    next = False\n",
    "    for content in contents:\n",
    "        if(content == item):\n",
    "            next = True\n",
    "    return next\n",
    "\n",
    "\n",
    "def findTopDataSet(dataSet):\n",
    "    unique = []\n",
    "    for x, y in dataSet:\n",
    "        new = True\n",
    "        i = 0\n",
    "        for u, l in unique:\n",
    "            if u == x:\n",
    "                new = False\n",
    "                l.append(y)\n",
    "                unique[i] = [u, l]\n",
    "            i+=1\n",
    "        if new:\n",
    "            unique.append([x,[y]])\n",
    "    result = []\n",
    "    for x, y in unique:\n",
    "        scores = []\n",
    "        for i in y:\n",
    "            new = True\n",
    "            numbersIndex = 0\n",
    "            for z, score in scores:\n",
    "                if i == z:\n",
    "                    new = False\n",
    "                    scores[numbersIndex] = [i, score+1]\n",
    "                numbersIndex += 1\n",
    "            scores.append([i, 0])\n",
    "        maxY = 0\n",
    "        topY =  scores[0][0]\n",
    "        for n, score in scores:\n",
    "            if(score > maxY):\n",
    "                maxY = score\n",
    "                topY = n\n",
    "        result.append([x,topY])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedClassContents = getSortedClass()\n",
    "saveClassesToFile(sortedClassContents)\n",
    "lenSortedClassContents = len(sortedClassContents)\n",
    "print(lenSortedClassContents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visitors_df = recommandation_df['visitor'].drop_duplicates()\n",
    "maxItem = recommandation_df['Content'].max()\n",
    "training_data = []\n",
    "for index, item in visitors_df.iteritems():\n",
    "    video = recommandation_df[recommandation_df['visitor'] == item]\n",
    "    if video.size > 1:\n",
    "        tempContents = []\n",
    "        indexContent = 0\n",
    "        for index, item in video['Content'].iteritems():\n",
    "            if(item not in sortedClassContents):\n",
    "                continue\n",
    "            if len(tempContents) > MAX_SEQUENCE: \n",
    "                tempContents = tempContents[1:]\n",
    "                continue\n",
    "            if(checkConsists(item, tempContents)):\n",
    "                continue\n",
    "            if len(tempContents) > 0:\n",
    "                nowDate = video['time'].iloc[indexContent]\n",
    "                beforeDate = video['time'].iloc[indexContent-1]\n",
    "                \n",
    "                if checkingTimeDifferent(nowDate, beforeDate):\n",
    "                    tempContents = []\n",
    "                else:\n",
    "                    feature = buildFeature(tempContents, sortedClassContents)\n",
    "                    label = sortedClassContents.index(item)\n",
    "                    training_data.append([[feature], label])\n",
    "            tempContents.append(item)\n",
    "            indexContent += 1\n",
    "\n",
    "training_data = findTopDataSet(training_data)\n",
    "print(\"training size: \", len(training_data))\n",
    "\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "labels = []\n",
    "for feature, label in training_data:\n",
    "    features.append(feature)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(features)\n",
    "Y = np.array(labels).astype(np.float32)\n",
    "X = np.squeeze(X, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"testing-1\"\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(name))\n",
    "model = Sequential()\n",
    "model.add(Embedding(lenSortedClassContents, 128, input_length=MAX_SEQUENCE))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(lenSortedClassContents, activation='softmax'))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.01)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "history = model.fit(X, Y, epochs=64, batch_size=32, verbose=1, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(first, second, third, forth, fifth, sixth):\n",
    "    predict = model.predict([[sortedClassContents.index(first),sortedClassContents.index(second),sortedClassContents.index(third),sortedClassContents.index(forth), sortedClassContents.index(fifth),sortedClassContents.index(sixth)]])\n",
    "    return sortedClassContents[np.argmax(predict[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictResult = predict(0,0,0,0,0,626)\n",
    "print(predictResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model = tf.function(lambda x: model(x))\n",
    "# This is important, let's fix the input size.\n",
    "BATCH_SIZE = 1\n",
    "STEPS = 100\n",
    "INPUT_SIZE = MAX_SEQUENCE\n",
    "concrete_func = run_model.get_concrete_function(\n",
    "    tf.TensorSpec([1,4], model.inputs[0].dtype))\n",
    "\n",
    "# model directory.\n",
    "MODEL_DIR = \"model\"\n",
    "model.save(MODEL_DIR, save_format=\"tf\", signatures=concrete_func)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model with TensorFlow to get expected results.\n",
    "TEST_CASES = 10\n",
    "\n",
    "# Run the model with TensorFlow Lite\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)\n",
    "print(input_details[0][\"index\"])\n",
    "for i in range(TEST_CASES):\n",
    "  expected = model.predict([[0,0,0,i]])\n",
    "  interpreter.set_tensor( input_details[0][\"index\"], np.array([[0,0,0,i]]).astype(np.float32))\n",
    "  interpreter.invoke()\n",
    "  result = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "\n",
    "  # Assert if the result of TFLite model is consistent with the TF model.\n",
    "  np.testing.assert_almost_equal(expected, result)\n",
    "  print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")\n",
    "\n",
    "  # Please note: TfLite fused Lstm kernel is stateful, so we need to reset\n",
    "  # the states.\n",
    "  # Clean up internal states.\n",
    "  interpreter.reset_all_variables()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor( input_details[0][\"index\"], np.array([[0,0,0,sortedClassContents.index(700)]]).astype(np.float32))\n",
    "interpreter.invoke()\n",
    "result = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "print(sortedClassContents[np.argmax(result)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
