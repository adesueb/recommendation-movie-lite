{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Activation, Embedding, Conv1D, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from dataprocessing.find_top_movie_with_sequence import find_top_dataset\n",
    "from dataprocessing.label_and_feature import getSortedClassContents, checkConsists, buildFeature, saveClassesToFile\n",
    "from dataprocessing.time import checkingTimeDifferent\n",
    "from recom_model import trainWithBidirectional,trainWithEmbeddingDense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CONTENTS_ON_USER = 250\n",
    "MAX_DAYS = 7\n",
    "MAX_SEQUENCE = 6\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "recommandation_df = pd.read_csv('{}/normalizedata.csv'.format(DATA_DIR)).sort_values(by=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedClassContents = getSortedClassContents(recommandation_df, MIN_CONTENTS_ON_USER)\n",
    "saveClassesToFile(sortedClassContents)\n",
    "lenSortedClassContents = len(sortedClassContents)\n",
    "print(lenSortedClassContents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visitors_df = recommandation_df['visitor'].drop_duplicates()\n",
    "maxItem = recommandation_df['Content'].max()\n",
    "training_data = []\n",
    "for index, item in visitors_df.iteritems():\n",
    "    video = recommandation_df[recommandation_df['visitor'] == item]\n",
    "    if video.size > 1:\n",
    "        tempContents = []\n",
    "        indexContent = 0\n",
    "        for index, item in video['Content'].iteritems():\n",
    "            if item not in sortedClassContents:\n",
    "                continue\n",
    "            if len(tempContents) > MAX_SEQUENCE:\n",
    "                tempContents = tempContents[1:]\n",
    "                continue\n",
    "            if checkConsists(item, tempContents):\n",
    "                continue\n",
    "            if len(tempContents) > 0:\n",
    "                nowDate = video['time'].iloc[indexContent]\n",
    "                beforeDate = video['time'].iloc[indexContent - 1]\n",
    "\n",
    "                if checkingTimeDifferent(nowDate, beforeDate, MAX_DAYS):\n",
    "                    tempContents = []\n",
    "                else:\n",
    "                    feature = buildFeature(tempContents, sortedClassContents, MAX_SEQUENCE)\n",
    "                    label = sortedClassContents.index(item)\n",
    "                    training_data.append([[feature], label])\n",
    "            tempContents.append(item)\n",
    "            indexContent += 1\n",
    "\n",
    "training_data = find_top_dataset(training_data)\n",
    "print(\"training size: \", len(training_data))\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "labels = []\n",
    "for feature, label in training_data:\n",
    "    features.append(feature)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(features)\n",
    "Y = np.array(labels)\n",
    "print(X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lstm with embedding\n",
    "X = np.squeeze(X, axis=1)\n",
    "model = trainWithBidirectional(MAX_SEQUENCE, lenSortedClassContents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pure lstm\n",
    "\n",
    "X = np.squeeze(X, axis=1)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=X.shape[1:], return_sequences=True) )\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(lenSortedClassContents))\n",
    "model.add(Activation(\"softmax\"))\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dense\n",
    "X = np.squeeze(X, axis=1)\n",
    "print(X.shape)\n",
    "model = Sequential()   \n",
    "model.add(Dense(512, activation=\"relu\", input_shape=(X.shape[1:])))\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dense(lenSortedClassContents))\n",
    "model.add(Activation(\"softmax\"))\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for embedding Dense\n",
    "X = np.squeeze(X, axis=1)\n",
    "model = trainWithEmbeddingDense(MAX_SEQUENCE, lenSortedClassContents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"testing-1\"\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(name))\n",
    "history = model.fit(X, Y, epochs=250, batch_size=64, verbose=1, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get5TopPredict(predict):\n",
    "    predicts = predict[0].argsort()[-5:][::-1]\n",
    "    for i in predicts:\n",
    "        print(sortedClassContents[i])\n",
    "        \n",
    "def predict(first, second, third, forth, fifth, sixth):\n",
    "    predict = model.predict([[[sortedClassContents.index(first)],[sortedClassContents.index(second)],[sortedClassContents.index(third)],[sortedClassContents.index(forth)], [sortedClassContents.index(fifth)],[sortedClassContents.index(sixth)]]])\n",
    "    get5TopPredict(predict)\n",
    "    return sortedClassContents[np.argmax(predict[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictResult = predictDense(0,0,0,0,700,1756)\n",
    "print(predictResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model = tf.function(lambda x: model(x))\n",
    "# This is important, let's fix the input size.\n",
    "concrete_func = run_model.get_concrete_function(\n",
    "    tf.TensorSpec([1,6], model.inputs[0].dtype))\n",
    "\n",
    "# model directory.\n",
    "MODEL_DIR = \"model\"\n",
    "model.save(MODEL_DIR, save_format=\"tf\", signatures=concrete_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"model\"\n",
    "model.save(MODEL_DIR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model with TensorFlow to get expected results.\n",
    "TEST_CASES = 10\n",
    "\n",
    "# Run the model with TensorFlow Lite\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)\n",
    "print(input_details[0][\"index\"])\n",
    "for i in range(TEST_CASES):\n",
    "  expected = model.predict([[0,0,0,i]])\n",
    "  interpreter.set_tensor( input_details[0][\"index\"], np.array([[0,0,0,i]]).astype(np.float32))\n",
    "  interpreter.invoke()\n",
    "  result = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "\n",
    "  # Assert if the result of TFLite model is consistent with the TF model.\n",
    "  np.testing.assert_almost_equal(expected, result)\n",
    "  print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")\n",
    "\n",
    "  # Please note: TfLite fused Lstm kernel is stateful, so we need to reset\n",
    "  # the states.\n",
    "  # Clean up internal states.\n",
    "  interpreter.reset_all_variables()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"tf_model/converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor( input_details[0][\"index\"], np.array([[0,0,0,sortedClassContents.index(700)]]).astype(np.float32))\n",
    "interpreter.invoke()\n",
    "result = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "print(sortedClassContents[np.argmax(result)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
