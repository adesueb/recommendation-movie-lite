{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[[[[0, 0, 0, 74]], 3], [[[0, 0, 0, 2]], 4], [[[0, 0, 2, 1]], 1], [[[0, 0, 0, 3]], 5], [[[0, 0, 0, 4]], 7], [[[0, 0, 0, 1]], 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional,BatchNormalization, Activation, Embedding, Conv1D, Flatten, MaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from dataprocessing.find_top_movie_no_sequence import find_top_dataset\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CONTENTS_ON_USER = 250\n",
    "MAX_DAYS = 7\n",
    "MAX_SEQUENCE = 6\n",
    "DATA_DIR = \"data\"\n",
    "recommandation_df = pd.read_csv('{}/normalizedata.csv'.format(DATA_DIR)).sort_values(by=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToTimemillis(date):\n",
    "    try:\n",
    "        d = datetime.datetime.strptime(date, \"%Y-%m-%d %H:%M:%S\").strftime('%s.%f')\n",
    "        return int(float(d)*1000)\n",
    "    except:\n",
    "        pass\n",
    "    return 0\n",
    "\n",
    "def getSortedClass():\n",
    "    levels = []\n",
    "    levels.append([0, MIN_CONTENTS_ON_USER+1])\n",
    "    contentLevels = recommandation_df['Content'].values\n",
    "    for contentLevel in contentLevels:\n",
    "        add = True\n",
    "        indexLevel = 0\n",
    "        for key, level in levels:\n",
    "            if contentLevel == key:\n",
    "                add = False\n",
    "                levels[indexLevel] = ([key, level+1])\n",
    "                break\n",
    "            else:\n",
    "                indexLevel+=1\n",
    "        if add:\n",
    "            levels.append([contentLevel, 1])\n",
    "\n",
    "    classContents = []\n",
    "    for key, level in levels:\n",
    "        if level > MIN_CONTENTS_ON_USER:\n",
    "            classContents.append(key)\n",
    "            \n",
    "    sortedClassContents = sorted(classContents)\n",
    "    print(sortedClassContents)\n",
    "    return sortedClassContents\n",
    "\n",
    "def saveClassesToFile(classes):\n",
    "    label_file = open(\"label.txt\", \"w\")\n",
    "    np.savetxt(label_file, classes)\n",
    "    label_file.close()\n",
    "\n",
    "\n",
    "def checkingTimeDifferent(nowDate, beforeDate):\n",
    "    now = convertToTimemillis(nowDate)\n",
    "    before = convertToTimemillis(beforeDate)\n",
    "    return (now - before) >  (MAX_DAYS * 86400000)\n",
    "\n",
    "\n",
    "def buildFeature(paramsContents, sortedClassContents):\n",
    "    feature = []\n",
    "    for ignore in range(MAX_SEQUENCE-len(paramsContents)):\n",
    "        feature.append(0)\n",
    "    for content in paramsContents:\n",
    "        feature.append(sortedClassContents.index(content))\n",
    "        \n",
    "    return feature\n",
    "\n",
    "def checkConsists(item, contents):\n",
    "    next = False\n",
    "    for content in contents:\n",
    "        if(content == item):\n",
    "            next = True\n",
    "    return next\n",
    "\n",
    "\n",
    "def findTopDataSet(dataSet):\n",
    "    unique = []\n",
    "    for x, y in dataSet:\n",
    "        new = True\n",
    "        i = 0\n",
    "        for u, l in unique:\n",
    "            if u == x:\n",
    "                new = False\n",
    "                l.append(y)\n",
    "                unique[i] = [u, l]\n",
    "            i+=1\n",
    "        if new:\n",
    "            unique.append([x,[y]])\n",
    "    result = []\n",
    "    for x, y in unique:\n",
    "        scores = []\n",
    "        for i in y:\n",
    "            new = True\n",
    "            numbersIndex = 0\n",
    "            for z, score in scores:\n",
    "                if i == z:\n",
    "                    new = False\n",
    "                    scores[numbersIndex] = [i, score+1]\n",
    "                numbersIndex += 1\n",
    "            scores.append([i, 0])\n",
    "        maxY = 0\n",
    "        topY =  scores[0][0]\n",
    "        for n, score in scores:\n",
    "            if(score > maxY):\n",
    "                maxY = score\n",
    "                topY = n\n",
    "        result.append([x,topY])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 15, 23, 39, 69, 79, 162, 169, 202, 205, 213, 252, 255, 306, 308, 312, 322, 369, 371, 379, 434, 448, 455, 478, 479, 480, 481, 492, 507, 513, 535, 548, 623, 626, 640, 644, 657, 682, 683, 697, 700, 752, 772, 776, 777, 781, 824, 832, 839, 883, 913, 936, 960, 964, 977, 989, 993, 1006, 1020, 1026, 1115, 1137, 1185, 1187, 1193, 1239, 1242, 1256, 1269, 1304, 1310, 1397, 1415, 1420, 1428, 1429, 1433, 1436, 1437, 1490, 1498, 1506, 1512, 1521, 1534, 1554, 1559, 1567, 1578, 1579, 1589, 1591, 1599, 1602, 1606, 1607, 1609, 1619, 1620, 1624, 1641, 1652, 1659, 1677, 1700, 1716, 1719, 1756, 1758, 1774, 1777, 1781, 1788, 1790, 1791, 1795, 1798, 1806, 1807, 1813, 1819, 1823, 1826, 1830, 1833, 1834, 1836, 1838, 1839, 1840, 1845, 1847, 1853, 1855, 1862, 1863, 1872, 1873, 1876, 1877, 1879, 1885, 1896, 1910, 1912, 1913, 1927, 1928, 1935, 1936]\n",
      "151\n"
     ]
    }
   ],
   "source": [
    "sortedClassContents = getSortedClass()\n",
    "saveClassesToFile(sortedClassContents)\n",
    "lenSortedClassContents = len(sortedClassContents)\n",
    "print(lenSortedClassContents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size:  8195\n"
     ]
    }
   ],
   "source": [
    "visitors_df = recommandation_df['visitor'].drop_duplicates()\n",
    "maxItem = recommandation_df['Content'].max()\n",
    "training_data = []\n",
    "for index, item in visitors_df.iteritems():\n",
    "    video = recommandation_df[recommandation_df['visitor'] == item]\n",
    "    if video.size > 1:\n",
    "        tempContents = []\n",
    "        indexContent = 0\n",
    "        for index, item in video['Content'].iteritems():\n",
    "            if(item not in sortedClassContents):\n",
    "                continue\n",
    "            if len(tempContents) > MAX_SEQUENCE: \n",
    "                tempContents = tempContents[1:]\n",
    "                continue\n",
    "            if(checkConsists(item, tempContents)):\n",
    "                continue\n",
    "            if len(tempContents) > 0:\n",
    "                nowDate = video['time'].iloc[indexContent]\n",
    "                beforeDate = video['time'].iloc[indexContent-1]\n",
    "                \n",
    "                if checkingTimeDifferent(nowDate, beforeDate):\n",
    "                    tempContents = []\n",
    "                else:\n",
    "                    feature = buildFeature(tempContents, sortedClassContents)\n",
    "                    label = sortedClassContents.index(item)\n",
    "                    training_data.append([[feature], label])\n",
    "            tempContents.append(item)\n",
    "            indexContent += 1\n",
    "\n",
    "training_data = find_top_dataset(training_data)\n",
    "print(\"training size: \", len(training_data))\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "labels = []\n",
    "for feature, label in training_data:\n",
    "    features.append(feature)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0   0   0 128  94 126]]\n",
      "\n",
      " [[ 30 145 144 140 120 119]]\n",
      "\n",
      " [[  0   0 101 144 112 125]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  0   0 130  58  55   2]]\n",
      "\n",
      " [[  0 117  29 106  42 116]]\n",
      "\n",
      " [[  0   0   0  23  62 140]]]\n",
      "(8195, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(features)\n",
    "Y = np.array(labels).astype(np.float32)\n",
    "print(X)\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lstm with embedding\n",
    "X = np.squeeze(X, axis=1)\n",
    "model = Sequential()\n",
    "model.add(Embedding(lenSortedClassContents, 128, input_length=MAX_SEQUENCE))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(lenSortedClassContents, activation='softmax'))\n",
    "# adam = Adam(lr=0.01)\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pure lstm\n",
    "\n",
    "X = np.squeeze(X, axis=1)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "print (X)\n",
    "print (X.shape)\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=X.shape[1:], return_sequences=True) )\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(lenSortedClassContents))\n",
    "model.add(Activation(\"softmax\"))\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8195, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "# for cnn\n",
    "X = np.squeeze(X, axis=1)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "model = Sequential()\n",
    "model.add(Conv1D(128, 1, activation=\"relu\", input_shape=X.shape[1:]))\n",
    "model.add(Conv1D(128, 1, activation=\"relu\"))\n",
    "model.add(Conv1D(128, 1, activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dense(lenSortedClassContents, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "  1/129 [..............................] - ETA: 0s - loss: 6.2355 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0021s vs `on_train_batch_end` time: 0.0404s). Check your callbacks.\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 4.9269 - accuracy: 0.0182\n",
      "Epoch 2/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 4.8573 - accuracy: 0.0204\n",
      "Epoch 3/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 4.8360 - accuracy: 0.0194\n",
      "Epoch 4/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 4.8218 - accuracy: 0.0220\n",
      "Epoch 5/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 4.7999 - accuracy: 0.0244\n",
      "Epoch 6/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 4.7795 - accuracy: 0.0250\n",
      "Epoch 7/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 4.7528 - accuracy: 0.0262\n",
      "Epoch 8/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 4.7216 - accuracy: 0.0266\n",
      "Epoch 9/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 4.6926 - accuracy: 0.0249\n",
      "Epoch 10/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 4.6682 - accuracy: 0.0303\n",
      "Epoch 11/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 4.6245 - accuracy: 0.0309\n",
      "Epoch 12/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 4.5880 - accuracy: 0.0337\n",
      "Epoch 13/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 4.5420 - accuracy: 0.0361\n",
      "Epoch 14/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 4.5210 - accuracy: 0.0395\n",
      "Epoch 15/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 4.4643 - accuracy: 0.0448\n",
      "Epoch 16/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 4.4272 - accuracy: 0.0439\n",
      "Epoch 17/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 4.3834 - accuracy: 0.0462\n",
      "Epoch 18/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 4.3108 - accuracy: 0.0549\n",
      "Epoch 19/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 4.2530 - accuracy: 0.0610\n",
      "Epoch 20/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 4.2046 - accuracy: 0.0631\n",
      "Epoch 21/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 4.1646 - accuracy: 0.0687\n",
      "Epoch 22/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 4.1187 - accuracy: 0.0752\n",
      "Epoch 23/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 4.0565 - accuracy: 0.0846\n",
      "Epoch 24/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 4.0246 - accuracy: 0.0891\n",
      "Epoch 25/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 3.9790 - accuracy: 0.0933\n",
      "Epoch 26/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 3.8687 - accuracy: 0.1082\n",
      "Epoch 27/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 3.7991 - accuracy: 0.1206\n",
      "Epoch 28/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 3.7231 - accuracy: 0.1386\n",
      "Epoch 29/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 3.7024 - accuracy: 0.1391\n",
      "Epoch 30/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 3.6467 - accuracy: 0.1480\n",
      "Epoch 31/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 3.5556 - accuracy: 0.1647\n",
      "Epoch 32/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 3.5130 - accuracy: 0.1752\n",
      "Epoch 33/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 3.4266 - accuracy: 0.1915\n",
      "Epoch 34/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 3.3576 - accuracy: 0.2050\n",
      "Epoch 35/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 3.3655 - accuracy: 0.2009\n",
      "Epoch 36/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 3.3231 - accuracy: 0.2100\n",
      "Epoch 37/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 3.2596 - accuracy: 0.2262\n",
      "Epoch 38/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 3.2355 - accuracy: 0.2314\n",
      "Epoch 39/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 3.1928 - accuracy: 0.2327\n",
      "Epoch 40/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 3.1348 - accuracy: 0.2459\n",
      "Epoch 41/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 3.1429 - accuracy: 0.2451\n",
      "Epoch 42/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 3.0471 - accuracy: 0.2700\n",
      "Epoch 43/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.9963 - accuracy: 0.2807\n",
      "Epoch 44/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 3.0145 - accuracy: 0.2708\n",
      "Epoch 45/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.9705 - accuracy: 0.2813\n",
      "Epoch 46/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.9117 - accuracy: 0.2960\n",
      "Epoch 47/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 2.9379 - accuracy: 0.2962\n",
      "Epoch 48/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.9265 - accuracy: 0.2879\n",
      "Epoch 49/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.9328 - accuracy: 0.2968\n",
      "Epoch 50/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.7807 - accuracy: 0.3185\n",
      "Epoch 51/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.7836 - accuracy: 0.3175\n",
      "Epoch 52/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 2.9294 - accuracy: 0.2844\n",
      "Epoch 53/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 2.7373 - accuracy: 0.3263\n",
      "Epoch 54/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 2.6939 - accuracy: 0.3363\n",
      "Epoch 55/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 2.6930 - accuracy: 0.3378\n",
      "Epoch 56/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.7056 - accuracy: 0.3375\n",
      "Epoch 57/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 2.6045 - accuracy: 0.3583\n",
      "Epoch 58/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 2.6329 - accuracy: 0.3489\n",
      "Epoch 59/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 2.5868 - accuracy: 0.3581\n",
      "Epoch 60/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.5603 - accuracy: 0.3597\n",
      "Epoch 61/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 2.5891 - accuracy: 0.3553\n",
      "Epoch 62/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.6110 - accuracy: 0.3423\n",
      "Epoch 63/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.5342 - accuracy: 0.3664\n",
      "Epoch 64/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.4879 - accuracy: 0.3741\n",
      "Epoch 65/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.4980 - accuracy: 0.3694\n",
      "Epoch 66/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.4309 - accuracy: 0.3818\n",
      "Epoch 67/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.4840 - accuracy: 0.3700\n",
      "Epoch 68/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.4653 - accuracy: 0.3751\n",
      "Epoch 69/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.4205 - accuracy: 0.3906\n",
      "Epoch 70/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.3650 - accuracy: 0.3966\n",
      "Epoch 71/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.3440 - accuracy: 0.3948\n",
      "Epoch 72/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.3773 - accuracy: 0.3924\n",
      "Epoch 73/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.3519 - accuracy: 0.3946\n",
      "Epoch 74/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.3601 - accuracy: 0.3902\n",
      "Epoch 75/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 2.3371 - accuracy: 0.3998\n",
      "Epoch 76/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 2.2892 - accuracy: 0.4103\n",
      "Epoch 77/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 2.2500 - accuracy: 0.4236\n",
      "Epoch 78/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 0s 2ms/step - loss: 2.2306 - accuracy: 0.4198\n",
      "Epoch 79/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.2089 - accuracy: 0.4283\n",
      "Epoch 80/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.2496 - accuracy: 0.4185\n",
      "Epoch 81/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 2.2170 - accuracy: 0.4251\n",
      "Epoch 82/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.2852 - accuracy: 0.4063\n",
      "Epoch 83/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.1879 - accuracy: 0.4277\n",
      "Epoch 84/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 2.5710 - accuracy: 0.3424\n",
      "Epoch 85/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 2.1222 - accuracy: 0.4376\n",
      "Epoch 86/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.0841 - accuracy: 0.4505\n",
      "Epoch 87/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.0647 - accuracy: 0.4534\n",
      "Epoch 88/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 2.0543 - accuracy: 0.4543\n",
      "Epoch 89/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 2.0242 - accuracy: 0.4620\n",
      "Epoch 90/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.1318 - accuracy: 0.4344\n",
      "Epoch 91/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.1050 - accuracy: 0.4398\n",
      "Epoch 92/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.0375 - accuracy: 0.4522\n",
      "Epoch 93/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 2.1653 - accuracy: 0.4231\n",
      "Epoch 94/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 2.1002 - accuracy: 0.4410\n",
      "Epoch 95/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.9772 - accuracy: 0.4700\n",
      "Epoch 96/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.9861 - accuracy: 0.4682\n",
      "Epoch 97/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.9948 - accuracy: 0.4604\n",
      "Epoch 98/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.9568 - accuracy: 0.4692\n",
      "Epoch 99/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 2.0843 - accuracy: 0.4432\n",
      "Epoch 100/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.9777 - accuracy: 0.4656\n",
      "Epoch 101/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.9998 - accuracy: 0.4632\n",
      "Epoch 102/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.9488 - accuracy: 0.4755\n",
      "Epoch 103/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 2.0059 - accuracy: 0.4627\n",
      "Epoch 104/256\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 1.8953 - accuracy: 0.4865\n",
      "Epoch 105/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.9150 - accuracy: 0.4846\n",
      "Epoch 106/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.9492 - accuracy: 0.4769\n",
      "Epoch 107/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.8865 - accuracy: 0.4859\n",
      "Epoch 108/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.8936 - accuracy: 0.4811\n",
      "Epoch 109/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.9827 - accuracy: 0.4643\n",
      "Epoch 110/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.8204 - accuracy: 0.5031\n",
      "Epoch 111/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.8070 - accuracy: 0.5001\n",
      "Epoch 112/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.9286 - accuracy: 0.4752\n",
      "Epoch 113/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.8723 - accuracy: 0.4885\n",
      "Epoch 114/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.9035 - accuracy: 0.4808\n",
      "Epoch 115/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.8172 - accuracy: 0.4957\n",
      "Epoch 116/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.8258 - accuracy: 0.4963\n",
      "Epoch 117/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.7859 - accuracy: 0.5021\n",
      "Epoch 118/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.8423 - accuracy: 0.4984\n",
      "Epoch 119/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.8179 - accuracy: 0.4958\n",
      "Epoch 120/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.8648 - accuracy: 0.4879\n",
      "Epoch 121/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.7534 - accuracy: 0.5135\n",
      "Epoch 122/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.7681 - accuracy: 0.5092\n",
      "Epoch 123/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.7465 - accuracy: 0.5149\n",
      "Epoch 124/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.7103 - accuracy: 0.5223\n",
      "Epoch 125/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 2.0843 - accuracy: 0.4431\n",
      "Epoch 126/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.7237 - accuracy: 0.5168\n",
      "Epoch 127/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.7224 - accuracy: 0.5119\n",
      "Epoch 128/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.7054 - accuracy: 0.5209\n",
      "Epoch 129/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.7606 - accuracy: 0.5118\n",
      "Epoch 130/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.8075 - accuracy: 0.4984\n",
      "Epoch 131/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.7304 - accuracy: 0.5173\n",
      "Epoch 132/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.6764 - accuracy: 0.5314\n",
      "Epoch 133/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.6437 - accuracy: 0.5356\n",
      "Epoch 134/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.6242 - accuracy: 0.5445\n",
      "Epoch 135/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.8905 - accuracy: 0.4857\n",
      "Epoch 136/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.6351 - accuracy: 0.5386\n",
      "Epoch 137/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.6083 - accuracy: 0.5490\n",
      "Epoch 138/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.8580 - accuracy: 0.4949\n",
      "Epoch 139/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.6735 - accuracy: 0.5252\n",
      "Epoch 140/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.7739 - accuracy: 0.5091\n",
      "Epoch 141/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.6409 - accuracy: 0.5348\n",
      "Epoch 142/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.5977 - accuracy: 0.5466\n",
      "Epoch 143/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.5884 - accuracy: 0.5483\n",
      "Epoch 144/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.5580 - accuracy: 0.5535\n",
      "Epoch 145/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.5738 - accuracy: 0.5503: 0s - loss: 1.4351 - accura\n",
      "Epoch 146/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.6005 - accuracy: 0.5467\n",
      "Epoch 147/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.7794 - accuracy: 0.5042\n",
      "Epoch 148/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.6435 - accuracy: 0.5245\n",
      "Epoch 149/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.7098 - accuracy: 0.5270\n",
      "Epoch 150/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.6623 - accuracy: 0.5403\n",
      "Epoch 151/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.5533 - accuracy: 0.5556\n",
      "Epoch 152/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.5447 - accuracy: 0.5589\n",
      "Epoch 153/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.5499 - accuracy: 0.5573\n",
      "Epoch 154/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.5014 - accuracy: 0.5663\n",
      "Epoch 155/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.5069 - accuracy: 0.5739\n",
      "Epoch 156/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.5411 - accuracy: 0.5599\n",
      "Epoch 157/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 0s 3ms/step - loss: 1.5827 - accuracy: 0.5489\n",
      "Epoch 158/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.5482 - accuracy: 0.5579\n",
      "Epoch 159/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.6121 - accuracy: 0.5402\n",
      "Epoch 160/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.6251 - accuracy: 0.5390\n",
      "Epoch 161/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.5544 - accuracy: 0.5555\n",
      "Epoch 162/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.6235 - accuracy: 0.5413\n",
      "Epoch 163/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.5144 - accuracy: 0.5629\n",
      "Epoch 164/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.4954 - accuracy: 0.5685\n",
      "Epoch 165/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.4849 - accuracy: 0.5743\n",
      "Epoch 166/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.5796 - accuracy: 0.5507\n",
      "Epoch 167/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.5634 - accuracy: 0.5567\n",
      "Epoch 168/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.5583 - accuracy: 0.5581\n",
      "Epoch 169/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.6050 - accuracy: 0.5470\n",
      "Epoch 170/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.4251 - accuracy: 0.5856\n",
      "Epoch 171/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.3930 - accuracy: 0.5900\n",
      "Epoch 172/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.4324 - accuracy: 0.5811\n",
      "Epoch 173/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.3867 - accuracy: 0.5900\n",
      "Epoch 174/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.5088 - accuracy: 0.5612\n",
      "Epoch 175/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.5571 - accuracy: 0.5594\n",
      "Epoch 176/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.7386 - accuracy: 0.5136\n",
      "Epoch 177/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.4908 - accuracy: 0.5646\n",
      "Epoch 178/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.4972 - accuracy: 0.5651\n",
      "Epoch 179/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.4388 - accuracy: 0.5852\n",
      "Epoch 180/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.4443 - accuracy: 0.5824\n",
      "Epoch 181/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.3972 - accuracy: 0.5891\n",
      "Epoch 182/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.3868 - accuracy: 0.5973\n",
      "Epoch 183/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.4089 - accuracy: 0.5896\n",
      "Epoch 184/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.3880 - accuracy: 0.5917\n",
      "Epoch 185/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.4088 - accuracy: 0.5874\n",
      "Epoch 186/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.4598 - accuracy: 0.5732\n",
      "Epoch 187/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.5911 - accuracy: 0.5444\n",
      "Epoch 188/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.4134 - accuracy: 0.5828\n",
      "Epoch 189/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.3171 - accuracy: 0.6129\n",
      "Epoch 190/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.4001 - accuracy: 0.5902\n",
      "Epoch 191/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.4088 - accuracy: 0.5876\n",
      "Epoch 192/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.5431 - accuracy: 0.5583\n",
      "Epoch 193/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.3298 - accuracy: 0.6055\n",
      "Epoch 194/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.5526 - accuracy: 0.5610\n",
      "Epoch 195/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.3127 - accuracy: 0.6084\n",
      "Epoch 196/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.2869 - accuracy: 0.6173\n",
      "Epoch 197/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.4134 - accuracy: 0.5891\n",
      "Epoch 198/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.4660 - accuracy: 0.5688\n",
      "Epoch 199/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.3741 - accuracy: 0.5933\n",
      "Epoch 200/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.5181 - accuracy: 0.5618\n",
      "Epoch 201/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.4035 - accuracy: 0.5877\n",
      "Epoch 202/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.6082 - accuracy: 0.5489\n",
      "Epoch 203/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.3607 - accuracy: 0.6043\n",
      "Epoch 204/256\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 1.3073 - accuracy: 0.6127\n",
      "Epoch 205/256\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 1.2919 - accuracy: 0.6165\n",
      "Epoch 206/256\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 1.2783 - accuracy: 0.6176\n",
      "Epoch 207/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.2356 - accuracy: 0.6278\n",
      "Epoch 208/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.4076 - accuracy: 0.5940\n",
      "Epoch 209/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.3484 - accuracy: 0.5973\n",
      "Epoch 210/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.3401 - accuracy: 0.6022\n",
      "Epoch 211/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.5447 - accuracy: 0.5607\n",
      "Epoch 212/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.3715 - accuracy: 0.5916\n",
      "Epoch 213/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.4411 - accuracy: 0.5823\n",
      "Epoch 214/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.6070 - accuracy: 0.5474\n",
      "Epoch 215/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.3297 - accuracy: 0.6066\n",
      "Epoch 216/256\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 1.2410 - accuracy: 0.6251\n",
      "Epoch 217/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.2576 - accuracy: 0.6290\n",
      "Epoch 218/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.2275 - accuracy: 0.6270\n",
      "Epoch 219/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.2694 - accuracy: 0.6240\n",
      "Epoch 220/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.2674 - accuracy: 0.6151\n",
      "Epoch 221/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.2724 - accuracy: 0.6183\n",
      "Epoch 222/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.4304 - accuracy: 0.5818\n",
      "Epoch 223/256\n",
      "129/129 [==============================] - 0s 2ms/step - loss: 1.2784 - accuracy: 0.6139\n",
      "Epoch 224/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.3001 - accuracy: 0.6111\n",
      "Epoch 225/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.3355 - accuracy: 0.6033\n",
      "Epoch 226/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.2911 - accuracy: 0.6131\n",
      "Epoch 227/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.3026 - accuracy: 0.6167\n",
      "Epoch 228/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.3549 - accuracy: 0.6085\n",
      "Epoch 229/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.3195 - accuracy: 0.6055\n",
      "Epoch 230/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.2849 - accuracy: 0.6154\n",
      "Epoch 231/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.2629 - accuracy: 0.6237\n",
      "Epoch 232/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.2469 - accuracy: 0.6240\n",
      "Epoch 233/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.2269 - accuracy: 0.6306\n",
      "Epoch 234/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.3015 - accuracy: 0.6160\n",
      "Epoch 235/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.3519 - accuracy: 0.5984\n",
      "Epoch 236/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 0s 3ms/step - loss: 1.4097 - accuracy: 0.5897\n",
      "Epoch 237/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.3059 - accuracy: 0.6110\n",
      "Epoch 238/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.2372 - accuracy: 0.6267\n",
      "Epoch 239/256\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 1.2391 - accuracy: 0.6205\n",
      "Epoch 240/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.2760 - accuracy: 0.6159\n",
      "Epoch 241/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.2166 - accuracy: 0.6318\n",
      "Epoch 242/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.1960 - accuracy: 0.6384\n",
      "Epoch 243/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.2110 - accuracy: 0.6349\n",
      "Epoch 244/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.1604 - accuracy: 0.6445\n",
      "Epoch 245/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.1525 - accuracy: 0.6454\n",
      "Epoch 246/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.2585 - accuracy: 0.6203\n",
      "Epoch 247/256\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 1.2380 - accuracy: 0.6246\n",
      "Epoch 248/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.4247 - accuracy: 0.5865\n",
      "Epoch 249/256\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 1.3813 - accuracy: 0.6004\n",
      "Epoch 250/256\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 1.2123 - accuracy: 0.6305\n",
      "Epoch 251/256\n",
      "129/129 [==============================] - 1s 5ms/step - loss: 1.1606 - accuracy: 0.6451\n",
      "Epoch 252/256\n",
      "129/129 [==============================] - 0s 3ms/step - loss: 1.2465 - accuracy: 0.6255\n",
      "Epoch 253/256\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 1.3308 - accuracy: 0.6095\n",
      "Epoch 254/256\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 1.1554 - accuracy: 0.6528\n",
      "Epoch 255/256\n",
      "129/129 [==============================] - 1s 4ms/step - loss: 1.2042 - accuracy: 0.6365\n",
      "Epoch 256/256\n",
      "129/129 [==============================] - 0s 4ms/step - loss: 1.2415 - accuracy: 0.6246\n"
     ]
    }
   ],
   "source": [
    "name = \"testing-1\"\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(name))\n",
    "history = model.fit(X, Y, epochs=256, batch_size=64, verbose=1, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(first, second, third, forth, fifth, sixth):\n",
    "    predict = model.predict([[[sortedClassContents.index(first)],[sortedClassContents.index(second)],[sortedClassContents.index(third)],[sortedClassContents.index(forth)], [sortedClassContents.index(fifth)],[sortedClassContents.index(sixth)]]])\n",
    "    return sortedClassContents[np.argmax(predict[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": " input depth must be evenly divisible by filter depth: 1 vs 6\n\t [[node sequential_4/conv1d_8/conv1d (defined at <ipython-input-30-7efab67b4c55>:2) ]] [Op:__inference_predict_function_144590]\n\nFunction call stack:\npredict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-8af937cf7d3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1756\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictResult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-7efab67b4c55>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(first, second, third, forth, fifth, sixth)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthird\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfifth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msixth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msortedClassContents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msortedClassContents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msecond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msortedClassContents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthird\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msortedClassContents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msortedClassContents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msortedClassContents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msixth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msortedClassContents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  input depth must be evenly divisible by filter depth: 1 vs 6\n\t [[node sequential_4/conv1d_8/conv1d (defined at <ipython-input-30-7efab67b4c55>:2) ]] [Op:__inference_predict_function_144590]\n\nFunction call stack:\npredict_function\n"
     ]
    }
   ],
   "source": [
    "predictResult = predict(0,0,0,0,0, 1756)\n",
    "print(predictResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model = tf.function(lambda x: model(x))\n",
    "# This is important, let's fix the input size.\n",
    "BATCH_SIZE = 1\n",
    "STEPS = 100\n",
    "INPUT_SIZE = MAX_SEQUENCE\n",
    "concrete_func = run_model.get_concrete_function(\n",
    "    tf.TensorSpec([1,4], model.inputs[0].dtype))\n",
    "\n",
    "# model directory.\n",
    "MODEL_DIR = \"model\"\n",
    "model.save(MODEL_DIR, save_format=\"tf\", signatures=concrete_func)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model with TensorFlow to get expected results.\n",
    "TEST_CASES = 10\n",
    "\n",
    "# Run the model with TensorFlow Lite\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)\n",
    "print(input_details[0][\"index\"])\n",
    "for i in range(TEST_CASES):\n",
    "  expected = model.predict([[0,0,0,i]])\n",
    "  interpreter.set_tensor( input_details[0][\"index\"], np.array([[0,0,0,i]]).astype(np.float32))\n",
    "  interpreter.invoke()\n",
    "  result = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "\n",
    "  # Assert if the result of TFLite model is consistent with the TF model.\n",
    "  np.testing.assert_almost_equal(expected, result)\n",
    "  print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")\n",
    "\n",
    "  # Please note: TfLite fused Lstm kernel is stateful, so we need to reset\n",
    "  # the states.\n",
    "  # Clean up internal states.\n",
    "  interpreter.reset_all_variables()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor( input_details[0][\"index\"], np.array([[0,0,0,sortedClassContents.index(700)]]).astype(np.float32))\n",
    "interpreter.invoke()\n",
    "result = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "print(sortedClassContents[np.argmax(result)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
