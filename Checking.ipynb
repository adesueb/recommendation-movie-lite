{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 15, 23, 39, 69, 79, 162, 169, 202, 205, 213, 252, 255, 306, 308, 312, 322, 369, 371, 379, 434, 448, 455, 478, 479, 480, 481, 492, 507, 513, 535, 548, 623, 626, 640, 644, 657, 682, 683, 697, 700, 752, 772, 776, 777, 781, 824, 832, 839, 883, 913, 936, 960, 964, 977, 989, 993, 1006, 1020, 1026, 1115, 1137, 1185, 1187, 1193, 1239, 1242, 1256, 1269, 1304, 1310, 1397, 1415, 1420, 1428, 1429, 1433, 1436, 1437, 1490, 1498, 1506, 1512, 1521, 1534, 1554, 1559, 1567, 1578, 1579, 1589, 1591, 1599, 1602, 1606, 1607, 1609, 1619, 1620, 1624, 1641, 1652, 1659, 1677, 1700, 1716, 1719, 1756, 1758, 1774, 1777, 1781, 1788, 1790, 1791, 1795, 1798, 1806, 1807, 1813, 1819, 1823, 1826, 1830, 1833, 1834, 1836, 1838, 1839, 1840, 1845, 1847, 1853, 1855, 1862, 1863, 1872, 1873, 1876, 1877, 1879, 1885, 1896, 1910, 1912, 1913, 1927, 1928, 1935, 1936]\n",
      "151\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "def convertToTimemillis(date):\n",
    "    try:\n",
    "        d = datetime.datetime.strptime(date, \"%Y-%m-%d %H:%M:%S\").strftime('%s.%f')\n",
    "        return int(float(d)*1000)\n",
    "    except:\n",
    "        pass\n",
    "    return 0\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "recommandation_df = pd.read_csv('{}/normalizedata.csv'.format(DATA_DIR)).sort_values(by=['time'])\n",
    "\n",
    "levels = []\n",
    "\n",
    "MIN_CONTENTS_ON_USER = 250 \n",
    "\n",
    "levels.append([0, MIN_CONTENTS_ON_USER+1])\n",
    "\n",
    "contentLevels = recommandation_df['Content'].values\n",
    "for contentLevel in contentLevels:\n",
    "    add = True\n",
    "    indexLevel = 0\n",
    "    for key, level in levels:\n",
    "        if contentLevel == key:\n",
    "            add = False\n",
    "            levels[indexLevel] = ([key, level+1])\n",
    "            break\n",
    "        else:\n",
    "            indexLevel+=1\n",
    "    if add:\n",
    "        levels.append([contentLevel, 1])\n",
    "\n",
    "classContents = []\n",
    "for key, level in levels:\n",
    "    if level > MIN_CONTENTS_ON_USER:\n",
    "        classContents.append(key)\n",
    "        \n",
    "sortedClassContents = sorted(classContents)\n",
    "print(sortedClassContents)\n",
    "print(len(sortedClassContents))\n",
    "# 1876"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(first, second, third, forth, fifth, sixth):\n",
    "    predict = model.predict([[sortedClassContents.index(first),sortedClassContents.index(second),sortedClassContents.index(third),sortedClassContents.index(forth), sortedClassContents.index(fifth),sortedClassContents.index(sixth)]])\n",
    "    return sortedClassContents[np.argmax(predict[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1877\n"
     ]
    }
   ],
   "source": [
    "predictResult = predict(0,0,0,0,0,1876)\n",
    "print(predictResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
